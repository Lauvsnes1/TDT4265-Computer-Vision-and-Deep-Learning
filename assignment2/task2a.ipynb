{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "0020c6f6-a541-4664-b516-d25ac23cb225",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a2f87a45",
    "execution_start": 1645107249307,
    "execution_millis": 1558,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport utils\nimport typing\nnp.random.seed(1)",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "fec0e4f6-475a-45ea-b638-b6694d3c3933",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "663e6ab8",
    "execution_start": 1645099428724,
    "execution_millis": 6,
    "deepnote_output_heights": [
     192,
     325
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def pre_process_images(X: np.ndarray):\n    \"\"\"\n    Args:\n        X: images of shape [batch size, 784] in the range (0, 255)\n    Returns:\n        X: images of shape [batch size, 785] normalized as described in task2a\n    \"\"\"\n    assert X.shape[1] == 784,\\\n        f\"X.shape[1]: {X.shape[1]}, should be 784\"\n    # TODO implement this function (Task 2a)\n    std = np.average(np.std(X, axis=0, dtype=float))\n    mean = np.average(np.mean(X, axis=0, dtype=float))\n    print('Standard deviation:', std)\n    print('Mean value:', mean)\n    X_norm = (X - mean)/std\n    \n    #bias trick\n    bias = np.ones((X.shape[0],1), dtype='float')\n    X_norm = np.append(X_norm, bias, axis=1)\n    return X_norm\n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "f4620fa9-efca-497e-845a-72e4617508eb",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8d326ba7",
    "execution_start": 1645107250878,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def cross_entropy_loss(targets: np.ndarray, outputs: np.ndarray):\n    \"\"\"\n    Args:\n        targets: labels/targets of each image of shape: [batch size, num_classes]\n        outputs: outputs of model of shape: [batch size, num_classes]\n    Returns:\n        Cross entropy error (float)\n    \"\"\"\n    assert targets.shape == outputs.shape,\\\n        f\"Targets shape: {targets.shape}, outputs: {outputs.shape}\"\n    # TODO: Implement this function (copy from last assignment)\n    return - np.sum(targets * np.log(outputs)) / targets.shape[0]\n",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "488f192c-ac4e-4ddd-9262-d9f26c5ddfcb",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4fd22b10",
    "execution_start": 1645099428786,
    "execution_millis": 43,
    "deepnote_output_heights": [
     21
    ],
    "deepnote_cell_type": "code"
   },
   "source": "def sigmoid(z):\n    return 1/(1+np.exp(-z))\n\ndef sigmoid_diff(z):\n    return sigmoid(z)*(1-sigmoid(z))\n\ndef improved_sigmoid(z):\n    print('hey')\n    return 1.7159*np.tanh(2/3*z)\n\ndef improved_sigmoid_diff(z):\n    print('yo')\n    return 1.7159 * 2/3 * (1-(np.tanh(2/3*z))**2)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "6a92d37f-f949-4105-afc0-e08a80110646",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "68d91b03",
    "execution_start": 1645099428872,
    "execution_millis": 61,
    "deepnote_output_heights": [
     325
    ],
    "deepnote_cell_type": "code"
   },
   "source": "class SoftmaxModel:\n\n    def __init__(self,\n                 # Number of neurons per layer\n                 neurons_per_layer: typing.List[int],\n                 use_improved_sigmoid: bool,  # Task 3a hyperparameter\n                 use_improved_weight_init: bool  # Task 3c hyperparameter\n                 ):\n        # Always reset random seed before weight init to get comparable results.\n        np.random.seed(1)\n        # Define number of input nodes\n        self.I = 785\n        self.use_improved_sigmoid = use_improved_sigmoid\n\n        # Define number of output nodes\n        # neurons_per_layer = [64, 10] indicates that we will have two layers:\n        # A hidden layer with 64 neurons and a output layer with 10 neurons.\n        self.neurons_per_layer = neurons_per_layer\n        \n\n\n        # Initialize the weights\n        self.ws = []\n        prev = self.I\n        if use_improved_weight_init:\n            for size in self.neurons_per_layer:\n                w_shape = (prev, size)\n                print(\"Initializing weight to shape:\", w_shape)\n                sigma = 1/np.sqrt(prev)\n                mu = 0\n                w = np.random.normal(mu, sigma, w_shape)\n                self.ws.append(w)\n                prev = size\n        else:\n            for size in self.neurons_per_layer:\n                #np.random.seed(0)\n                w_shape = (prev, size)\n                print(\"Initializing weight to shape:\", w_shape)\n                w = np.random.uniform(-1,1, (w_shape))\n                self.ws.append(w)\n                prev = size\n                \n        self.grads = [None for i in range(len(self.ws))]\n        self.z_arr = [None for i in range(len(self.ws))]\n        self.activations = [None for i in range(len(self.ws))]\n        self.delta = [None for i in range(len(self.ws))]\n\n        \n    def forward(self, X: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Args:\n            X: images of shape [batch size, 785]\n        Returns:\n            y: output of model with shape [batch size, num_outputs]\n        \"\"\"\n        # TODO implement this function (Task 2b)\n        # HINT: For performing the backward pass, you can save intermediate activations in variables in the forward pass.\n        # such as self.hidden_layer_output = ...\n        # Task 2b \n\n        a_i = X\n        softmax = lambda z : np.exp(z)/ (np.sum(np.exp(z), keepdims=True, axis=1))\n        \n        for i in range(len(self.ws)-1):\n            z = np.dot(a_i, self.ws[i])\n            if self.use_improved_sigmoid:\n                a_i = improved_sigmoid(z)                \n            else:\n                a_i = sigmoid(z)\n            self.z_arr[i]= z\n            self.activations[i]=a_i\n\n        z = np.dot(a_i, self.ws[-1])\n        a_i = softmax(z)\n        self.z_arr[-1] = z   \n        self.activations[-1] = a_i\n        return a_i\n         \n    def backward(self, X: np.ndarray, outputs: np.ndarray,\n                 targets: np.ndarray) -> None:\n        \"\"\"\n        Computes the gradient and saves it to the variable self.grad\n\n        Args:\n            X: images of shape [batch size, 785]\n            outputs: outputs of model of shape: [batch size, num_outputs]\n            targets: labels/targets of each image of shape: [batch size, num_classes]\n        \"\"\"\n\n        # TODO implement this function (Task 2b)\n        assert targets.shape == outputs.shape,\\\n            f\"Output shape: {outputs.shape}, targets: {targets.shape}\"\n\n\n        #Start with last layer gradient:\n        last_index = -1\n        self.delta[last_index] = -(targets - outputs)\n        self.grads[last_index] = np.dot(self.activations[last_index-1].T, self.delta[last_index])/(X.shape[0])\n\n        for i in range(len(self.ws)-2, 0, - 1):\n            if self.use_improved_sigmoid:                \n                self.delta[i] = np.dot(self.delta[i+1], self.ws[i+1].T)*improved_sigmoid_diff(self.z_arr[i])\n            else:                    \n                self.delta[i] = np.dot(self.delta[i+1], self.ws[i+1].T)*sigmoid_diff(self.z_arr[i])\n            self.grads[i] = np.dot(self.activations[i-1].T, self.delta[i])/X.shape[0] \n        \n        #first layer (hardkodet)\n        if self.use_improved_sigmoid:            \n            self.delta[0] = np.dot(self.delta[1], self.ws[1].T)*improved_sigmoid_diff(self.z_arr[0])\n        else:            \n            self.delta[0] = np.dot(self.delta[1], self.ws[1].T)*sigmoid_diff(self.z_arr[0])\n        self.grads[0] = np.dot(X.T, self.delta[0])/X.shape[0]\n\n        for grad, w in zip(self.grads, self.ws):\n            assert grad.shape == w.shape,\\\n                f\"Expected the same shape. Grad shape: {grad.shape}, w: {w.shape}.\"\n    \n       \n        \n    def zero_grad(self) -> None:\n        self.grads = [None for i in range(len(self.ws))]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5ab7a344-6e39-4c76-96e5-6b2a83c8d31b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7de1d4bf",
    "execution_start": 1645099428989,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def one_hot_encode(Y: np.ndarray, num_classes: int):\n    \"\"\"\n    Args:\n        Y: shape [Num examples, 1]\n        num_classes: Number of classes to use for one-hot encoding\n    Returns:\n        Y: shape [Num examples, num classes]\n    \"\"\"\n    # TODO implement this function (Task 3a) \n    res = np.zeros((len(Y),num_classes), dtype=int)\n    for i in range(len(Y)):\n        num_indx = Y[i] \n        res[i, num_indx] = 1\n    return res\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "db3f06d4-5885-4790-9e45-7e4b37c82bec",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5c0b1faf",
    "execution_start": 1645099428989,
    "execution_millis": 44,
    "deepnote_cell_type": "code"
   },
   "source": "def gradient_approximation_test(\n        model: SoftmaxModel, X: np.ndarray, Y: np.ndarray):\n    \"\"\"\n        Numerical approximation for gradients. Should not be edited. \n        Details about this test is given in the appendix in the assignment.\n    \"\"\"\n    epsilon = 1e-3\n    for layer_idx, w in enumerate(model.ws):\n        for i in range(w.shape[0]):\n            for j in range(w.shape[1]):\n                orig = model.ws[layer_idx][i, j].copy()\n                model.ws[layer_idx][i, j] = orig + epsilon\n                logits = model.forward(X)\n                cost1 = cross_entropy_loss(Y, logits)\n                model.ws[layer_idx][i, j] = orig - epsilon\n                logits = model.forward(X)\n                cost2 = cross_entropy_loss(Y, logits)\n                gradient_approximation = (cost1 - cost2) / (2 * epsilon)\n                model.ws[layer_idx][i, j] = orig\n                # Actual gradient\n                logits = model.forward(X)\n                model.backward(X, logits, Y)\n                difference = gradient_approximation - \\\n                    model.grads[layer_idx][i, j]\n                assert abs(difference) <= epsilon**2,\\\n                    f\"Calculated gradient is incorrect. \" \\\n                    f\"Layer IDX = {layer_idx}, i={i}, j={j}.\\n\" \\\n                    f\"Approximation: {gradient_approximation}, actual gradient: {model.grads[layer_idx][i, j]}\\n\" \\\n                    f\"If this test fails there could be errors in your cross entropy loss function, \" \\\n                    f\"forward function or backward function\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "58eea2df-0a14-49e3-9509-36f50d6f9381",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fedef72e",
    "execution_start": 1645099429033,
    "execution_millis": 10,
    "deepnote_output_heights": [
     21
    ],
    "deepnote_cell_type": "code"
   },
   "source": "'''\nif __name__ == \"__main__\":\n    # Simple test on one-hot encoding\n    Y = np.zeros((1, 1), dtype=int)\n    Y[0, 0] = 3\n    Y = one_hot_encode(Y, 10)\n    assert Y[0, 3] == 1 and Y.sum() == 1, \\\n        f\"Expected the vector to be [0,0,0,1,0,0,0,0,0,0], but got {Y}\"\n\n    X_train, Y_train, *_ = utils.load_full_mnist()\n    X_train = pre_process_images(X_train)\n    Y_train = one_hot_encode(Y_train, 10)\n    assert X_train.shape[1] == 785,\\\n        f\"Expected X_train to have 785 elements per image. Shape was: {X_train.shape}\"\n\n    neurons_per_layer = [64, 10]\n    use_improved_sigmoid = False\n    use_improved_weight_init = False\n    model = SoftmaxModel(\n        neurons_per_layer, use_improved_sigmoid, use_improved_weight_init)\n\n    # Gradient approximation check for 100 images\n    X_train = X_train[:100]\n    Y_train = Y_train[:100]\n    for layer_idx, w in enumerate(model.ws):\n        model.ws[layer_idx] = np.random.uniform(-1, 1, size=w.shape)\n\n    gradient_approximation_test(model, X_train, Y_train)\n'''\n",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "'\\nif __name__ == \"__main__\":\\n    # Simple test on one-hot encoding\\n    Y = np.zeros((1, 1), dtype=int)\\n    Y[0, 0] = 3\\n    Y = one_hot_encode(Y, 10)\\n    assert Y[0, 3] == 1 and Y.sum() == 1,         f\"Expected the vector to be [0,0,0,1,0,0,0,0,0,0], but got {Y}\"\\n\\n    X_train, Y_train, *_ = utils.load_full_mnist()\\n    X_train = pre_process_images(X_train)\\n    Y_train = one_hot_encode(Y_train, 10)\\n    assert X_train.shape[1] == 785,        f\"Expected X_train to have 785 elements per image. Shape was: {X_train.shape}\"\\n\\n    neurons_per_layer = [64, 10]\\n    use_improved_sigmoid = False\\n    use_improved_weight_init = False\\n    model = SoftmaxModel(\\n        neurons_per_layer, use_improved_sigmoid, use_improved_weight_init)\\n\\n    # Gradient approximation check for 100 images\\n    X_train = X_train[:100]\\n    Y_train = Y_train[:100]\\n    for layer_idx, w in enumerate(model.ws):\\n        model.ws[layer_idx] = np.random.uniform(-1, 1, size=w.shape)\\n\\n    gradient_approximation_test(model, X_train, Y_train)\\n'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=fc7fa119-6ed4-4d50-aa34-54bc46270896' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "2de91f6b-2ba4-4ea0-bcda-f72a4995905d",
  "deepnote_execution_queue": []
 }
}
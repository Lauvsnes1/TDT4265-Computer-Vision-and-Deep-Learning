{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Intersect over union is an evaluation metric which is used to measure accuracy for an object detector on a dataset. It calculates the difference between ground truth and the predicted bounding box by:\n",
    "- calculating the area of intersection\n",
    "- Calculate the total union area\n",
    "- then $ IoU = \\frac{\\text{area of intersect}}{ \\text{area of union}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Recall is another metric of precision used in object detection. This indicates the ability to find the ground truths, but doesnÂ´t take in to account the objects that are overlooked. \n",
    "\n",
    "$ Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    " Precision however, are only how many relevant predictions the network can make. This means how many true positives there are in all the detections.\n",
    "\n",
    "$ Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "\n",
    "\n",
    " True positives are objects detected which corresponds with the ground truth(correct prediction on correct object). False positives are when the network labels an object when it is not present(desired prediction on wrong object).   \n",
    "\n",
    "\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Firstly, we make a sorted table with precision and recall:\n",
    "\n",
    "Class 1: \n",
    "| no. | precision | recall|\n",
    "|:-----:|:----:|:-----:|\n",
    "|  1   |  1.0   | 0.05  |\n",
    "|   2  |  1.0   | 0.1  |\n",
    "|   3  | 1.0    | 0.4  |\n",
    "|   4  |   0.50  |  0.7 |\n",
    "|   5  |   0.20  | 1.0  |\n",
    "\n",
    "Then we use the 11 point interpolation to find the Average presicion:\n",
    "\n",
    "$ AP_1 = \\frac{1}{11}(1 \\times 4 + 0.5 \\times 4 + 0.2 \\times 3) = \\frac{3}{5} = 60 \\% $\n",
    "\n",
    "Class 2: \n",
    "| no. | precision | recall|\n",
    "|:-----:|:----:|:-----:|\n",
    "|  1   |  1.0   | 0.3  |\n",
    "|   2  |  0.8   | 0.4  |\n",
    "|   3  |  0.6   | 0.5  |\n",
    "|   4  |   0.50 |  0.7 |\n",
    "|   5  |   0.20 | 1.0  |\n",
    "\n",
    "Then we use the 11 point interpolation to find the Average presicion:\n",
    "\n",
    "$ AP_2 = \\frac{1}{11}(1 \\times 3 + 0.8 \\times 1 + 0.6 \\times 1 + 0.5 \\times 2 + 0.2 \\times 3) = \\frac{26}{55} = 47.3 \\% $\n",
    "\n",
    "Thus, the mean average percision(mAP) is $ \\frac{1}{n} \\Sigma AP$, where n is number of classes.\n",
    "\n",
    "$ mAP = \\frac{0.6 + \\frac{22}{55}}{2} =  \\underline{\\underline{53.6}} \\%$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "\n",
    "![](./task2/precision_recall_curve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "\n",
    "This filtering operation is called Non-maximum suppression (NMS)\n",
    "\n",
    "### Task 3b)\n",
    "**Is the following true or false: Predictions from the deeper layers in SSD are responsible to\n",
    "detect small objects.**\n",
    "\n",
    "This is false because the deeper layers have lower resolution and are therefore responsible to detect large objects. High resolution feature maps are responsible to detect small objects.\n",
    "\n",
    "### Task 3c)\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "### Task 3e)\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "### Task 3f)\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "FILL IN ANSWER. \n",
    "\n",
    "## Task 4c)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}